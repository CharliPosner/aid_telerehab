{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import deepdish as dd\n",
    "import csv\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pickle\n",
    "\n",
    "\n",
    "class PickleProtocol:\n",
    "    def __init__(self, level):\n",
    "        self.previous = pickle.HIGHEST_PROTOCOL\n",
    "        self.level = level\n",
    "\n",
    "    def __enter__(self):\n",
    "        importlib.reload(pickle)\n",
    "        pickle.HIGHEST_PROTOCOL = self.level\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        importlib.reload(pickle)\n",
    "        pickle.HIGHEST_PROTOCOL = self.previous\n",
    "\n",
    "\n",
    "def pickle_protocol(level):\n",
    "    return PickleProtocol(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>clinical TS Ex#1</th>\n",
       "      <th>clinical TS Ex#2</th>\n",
       "      <th>clinical TS Ex#3</th>\n",
       "      <th>clinical TS Ex#4</th>\n",
       "      <th>clinical TS Ex#5</th>\n",
       "      <th>clinical PO Ex#1</th>\n",
       "      <th>clinical PO Ex#2</th>\n",
       "      <th>clinical PO Ex#3</th>\n",
       "      <th>clinical PO Ex#4</th>\n",
       "      <th>clinical PO Ex#5</th>\n",
       "      <th>clinical CF Ex#1</th>\n",
       "      <th>clinical CF Ex#2</th>\n",
       "      <th>clinical CF Ex#3</th>\n",
       "      <th>clinical CF Ex#4</th>\n",
       "      <th>clinical CF Ex#5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B_ID1</td>\n",
       "      <td>B</td>\n",
       "      <td>66</td>\n",
       "      <td>F</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_ID2</td>\n",
       "      <td>B</td>\n",
       "      <td>52</td>\n",
       "      <td>M</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_ID3</td>\n",
       "      <td>B</td>\n",
       "      <td>78</td>\n",
       "      <td>F</td>\n",
       "      <td>28.210081</td>\n",
       "      <td>31.605061</td>\n",
       "      <td>25.178138</td>\n",
       "      <td>29.462784</td>\n",
       "      <td>16.245854</td>\n",
       "      <td>9.394392</td>\n",
       "      <td>10.063701</td>\n",
       "      <td>0.425665</td>\n",
       "      <td>10.187079</td>\n",
       "      <td>0.005147</td>\n",
       "      <td>18.815689</td>\n",
       "      <td>21.541360</td>\n",
       "      <td>24.752473</td>\n",
       "      <td>19.275704</td>\n",
       "      <td>16.240707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_ID4</td>\n",
       "      <td>B</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>33.339733</td>\n",
       "      <td>31.299278</td>\n",
       "      <td>38.358822</td>\n",
       "      <td>36.262890</td>\n",
       "      <td>32.118419</td>\n",
       "      <td>7.783826</td>\n",
       "      <td>10.755795</td>\n",
       "      <td>10.998189</td>\n",
       "      <td>11.997940</td>\n",
       "      <td>1.913925</td>\n",
       "      <td>25.555907</td>\n",
       "      <td>20.543484</td>\n",
       "      <td>27.360633</td>\n",
       "      <td>24.264950</td>\n",
       "      <td>30.204493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_ID5</td>\n",
       "      <td>B</td>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>44.333333</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>NE_ID5</td>\n",
       "      <td>NE</td>\n",
       "      <td>31</td>\n",
       "      <td>M</td>\n",
       "      <td>40.666667</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>11.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>NE_ID6</td>\n",
       "      <td>NE</td>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>43.666667</td>\n",
       "      <td>42.666667</td>\n",
       "      <td>42.333333</td>\n",
       "      <td>29.333333</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>21.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NE_ID7</td>\n",
       "      <td>NE</td>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NE_ID8</td>\n",
       "      <td>NE</td>\n",
       "      <td>58</td>\n",
       "      <td>F</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>NE_ID9</td>\n",
       "      <td>NE</td>\n",
       "      <td>46</td>\n",
       "      <td>M</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject ID Group  Age  Gender  clinical TS Ex#1  clinical TS Ex#2  \\\n",
       "0       B_ID1     B    66      F         41.000000         16.000000   \n",
       "1       B_ID2     B    52      M         38.000000         45.000000   \n",
       "2       B_ID3     B    78      F         28.210081         31.605061   \n",
       "3       B_ID4     B    52      F         33.339733         31.299278   \n",
       "4       B_ID5     B    72      M         44.333333         35.000000   \n",
       "..        ...   ...   ...    ...               ...               ...   \n",
       "73     NE_ID5    NE    31      M         40.666667         28.666667   \n",
       "74     NE_ID6    NE    28      M         43.666667         42.666667   \n",
       "75     NE_ID7    NE    26      M         42.000000         30.000000   \n",
       "76     NE_ID8    NE    58      F         40.000000         26.000000   \n",
       "77     NE_ID9    NE    46      M         42.000000         49.000000   \n",
       "\n",
       "    clinical TS Ex#3  clinical TS Ex#4  clinical TS Ex#5  clinical PO Ex#1  \\\n",
       "0          26.000000         23.000000         22.000000         15.000000   \n",
       "1          35.000000         26.000000         36.000000         12.000000   \n",
       "2          25.178138         29.462784         16.245854          9.394392   \n",
       "3          38.358822         36.262890         32.118419          7.783826   \n",
       "4          36.666667         40.000000         43.333333         13.000000   \n",
       "..               ...               ...               ...               ...   \n",
       "73         38.000000         31.333333         21.333333         13.000000   \n",
       "74         42.333333         29.333333         33.000000         14.000000   \n",
       "75         41.000000         33.000000         39.000000         15.000000   \n",
       "76         33.000000         26.000000         42.000000         15.000000   \n",
       "77         50.000000         34.000000         39.000000         15.000000   \n",
       "\n",
       "    clinical PO Ex#2  clinical PO Ex#3  clinical PO Ex#4  clinical PO Ex#5  \\\n",
       "0           5.000000          9.000000          4.000000          5.000000   \n",
       "1          15.000000          8.000000          3.000000         13.000000   \n",
       "2          10.063701          0.425665         10.187079          0.005147   \n",
       "3          10.755795         10.998189         11.997940          1.913925   \n",
       "4          10.666667         12.333333         10.333333         12.333333   \n",
       "..               ...               ...               ...               ...   \n",
       "73          9.000000          9.666667          9.000000          9.666667   \n",
       "74         12.666667         13.333333          7.000000         11.333333   \n",
       "75          9.000000         15.000000          3.000000         12.000000   \n",
       "76          5.000000         12.000000          3.000000         15.000000   \n",
       "77         14.000000         15.000000          3.000000         12.000000   \n",
       "\n",
       "    clinical CF Ex#1  clinical CF Ex#2  clinical CF Ex#3  clinical CF Ex#4  \\\n",
       "0          26.000000         11.000000         17.000000         19.000000   \n",
       "1          26.000000         30.000000         27.000000         23.000000   \n",
       "2          18.815689         21.541360         24.752473         19.275704   \n",
       "3          25.555907         20.543484         27.360633         24.264950   \n",
       "4          31.333333         24.333333         24.333333         29.666667   \n",
       "..               ...               ...               ...               ...   \n",
       "73         27.666667         19.666667         28.333333         22.333333   \n",
       "74         29.666667         30.000000         29.000000         22.333333   \n",
       "75         27.000000         21.000000         26.000000         30.000000   \n",
       "76         25.000000         21.000000         21.000000         23.000000   \n",
       "77         27.000000         35.000000         35.000000         31.000000   \n",
       "\n",
       "    clinical CF Ex#5  \n",
       "0          17.000000  \n",
       "1          23.000000  \n",
       "2          16.240707  \n",
       "3          30.204493  \n",
       "4          31.000000  \n",
       "..               ...  \n",
       "73         11.666667  \n",
       "74         21.666667  \n",
       "75         27.000000  \n",
       "76         27.000000  \n",
       "77         27.000000  \n",
       "\n",
       "[78 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rootdir = os.getcwd()\n",
    "searchstring = '\\\\Es1\\\\Label'\n",
    "\n",
    "clinical_assessment_files = []\n",
    "supplementary_info_files = []\n",
    "\n",
    "for rootdir, dirs, files in os.walk(rootdir):\n",
    "    for subdir in dirs:\n",
    "        subdir_name = os.path.join(rootdir, subdir)\n",
    "        if searchstring in subdir_name:\n",
    "            onlyfiles = [f for f in os.listdir(subdir_name) if os.path.isfile(os.path.join(subdir_name, f))]\n",
    "            clinical_assessment_files.append(os.path.join(subdir_name, onlyfiles[0]))\n",
    "            supplementary_info_files.append(os.path.join(subdir_name, onlyfiles[1]))\n",
    "\n",
    "\n",
    "suppinfo = []\n",
    "clinical = []\n",
    "\n",
    "for file in supplementary_info_files:\n",
    "    data = pd.read_excel(file)\n",
    "    suppinfo.append(data)\n",
    "    \n",
    "for file in clinical_assessment_files:\n",
    "    data = pd.read_excel(file)\n",
    "    clinical.append(data)\n",
    "    \n",
    "suppinfo_df = pd.concat(suppinfo, ignore_index=True)\n",
    "clinical_df = pd.concat(clinical, ignore_index=True)\n",
    "\n",
    "kimore_df = suppinfo_df.merge(clinical_df, on='Subject ID')\n",
    "\n",
    "display(kimore_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(total_score):\n",
    "    if (total_score > 44):\n",
    "        return 3\n",
    "    elif (total_score <= 44 and total_score > 34): \n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uneven_rating(total_score):\n",
    "    if (total_score > 37):\n",
    "        return 3\n",
    "    elif (total_score <= 37 and total_score > 25): \n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_from_filename(filename):\n",
    "    file_info = filename.split('_')\n",
    "    group = file_info[0]\n",
    "    subject_id = file_info[1]\n",
    "    exercise = file_info[2].split('.')[0]\n",
    "    return group, subject_id, int(exercise[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_from_filename_seq(filename):\n",
    "    file_info = filename.split('_')\n",
    "    group = file_info[0]\n",
    "    subject_id = file_info[1]\n",
    "    exercise = file_info[2]\n",
    "    sequence = file_info[3].split('.')[0][-1:]\n",
    "    return group, subject_id, int(exercise[2]), int(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_images_dir = os.path.join(os.getcwd(), 'kimore224norm_blazepose_xyz_noOverlap')\n",
    "file_list = []\n",
    "dict_list = []\n",
    "\n",
    "for item in os.scandir(resnet_images_dir):\n",
    "    if item.is_file():\n",
    "        # filename\n",
    "        filename = item.name\n",
    "        file_list.append(filename)\n",
    "        \n",
    "        # group, ID, exercise\n",
    "        group, subject_id, exercise, sequence = info_from_filename_seq(filename)\n",
    "        \n",
    "        # image as ndarrray\n",
    "        filepath = os.path.join(resnet_images_dir, filename)\n",
    "        image = np.asarray(Image.open(filepath))\n",
    "        \n",
    "        # TS, PO, CF\n",
    "        subject_entry = kimore_df[(kimore_df['Subject ID'].str.contains(subject_id)) & (kimore_df['Group'].str.contains(group))]\n",
    "        exercise_entry = [col for col in subject_entry.columns if str(exercise) in col]\n",
    "        total_score = round(subject_entry[exercise_entry[0]].values[0], 2)\n",
    "        primary_outcome = round(subject_entry[exercise_entry[1]].values[0], 2)\n",
    "        control_factor = round(subject_entry[exercise_entry[2]].values[0], 2)\n",
    "        \n",
    "        # rating\n",
    "        #rating_val = rating(total_score)\n",
    "        rating_val = uneven_rating(total_score)\n",
    "        \n",
    "        # onehot encodings\n",
    "        rating_onehot = np.zeros(3)\n",
    "        rating_onehot[rating_val - 1] = 1        \n",
    "        exercise_onehot = np.zeros(5)\n",
    "        exercise_onehot[exercise - 1] = 1\n",
    "        \n",
    "        # make dict\n",
    "        filename = {\n",
    "            \"image\": image,\n",
    "            \"group\": group,\n",
    "            \"subject_id\": subject_id,\n",
    "            \"slice\": sequence,\n",
    "            \"TS\": total_score,\n",
    "            \"PO\": primary_outcome,\n",
    "            \"CF\": control_factor,\n",
    "            \"rating\": rating_val,\n",
    "            \"rating_onehot\": rating_onehot,\n",
    "            \"exercise\": exercise,\n",
    "            \"exercise_onehot\": exercise_onehot\n",
    "        }\n",
    "        dict_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_images_dir = os.path.join(os.getcwd(), 'resnet_images')\n",
    "# file_list = []\n",
    "# dict_list = []\n",
    "\n",
    "# for item in os.scandir(resnet_images_dir):\n",
    "#     if item.is_file():\n",
    "#         # filename\n",
    "#         filename = item.name\n",
    "#         file_list.append(filename)\n",
    "        \n",
    "#         # group, ID, exercise\n",
    "#         group, subject_id, exercise = info_from_filename(filename)\n",
    "        \n",
    "#         # image as ndarrray\n",
    "#         filepath = os.path.join(resnet_images_dir, filename)\n",
    "#         image = np.asarray(Image.open(filepath))\n",
    "        \n",
    "#         # TS, PO, CF\n",
    "#         subject_entry = kimore_df[(kimore_df['Subject ID'].str.contains(subject_id)) & (kimore_df['Group'].str.contains(group))]\n",
    "#         exercise_entry = [col for col in subject_entry.columns if str(exercise) in col]\n",
    "#         total_score = round(subject_entry[exercise_entry[0]].values[0], 2)\n",
    "#         primary_outcome = round(subject_entry[exercise_entry[1]].values[0], 2)\n",
    "#         control_factor = round(subject_entry[exercise_entry[2]].values[0], 2)\n",
    "        \n",
    "#         # rating\n",
    "#         rating_val = rating(total_score)\n",
    "        \n",
    "#         # onehot encodings\n",
    "#         rating_onehot = np.zeros(3)\n",
    "#         rating_onehot[rating_val - 1] = 1        \n",
    "#         exercise_onehot = np.zeros(5)\n",
    "#         exercise_onehot[exercise - 1] = 1\n",
    "        \n",
    "#         # make dict\n",
    "#         filename = {\n",
    "#             \"image\": image,\n",
    "#             \"group\": group,\n",
    "#             \"subject_id\": subject_id,\n",
    "#             \"TS\": total_score,\n",
    "#             \"PO\": primary_outcome,\n",
    "#             \"CF\": control_factor,\n",
    "#             \"rating\": rating_val,\n",
    "#             \"rating_onehot\": rating_onehot,\n",
    "#             \"exercise\": exercise,\n",
    "#             \"exercise_onehot\": exercise_onehot\n",
    "#         }\n",
    "#         dict_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kimore224norm_blazepose_xyz_noOverlap_filenames.txt', 'w') as f:\n",
    "    for file in file_list:\n",
    "        f.write(f\"{file} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# with pickle_protocol(4):\n",
    "    #pd.DataFrame(['hello', 'world']).to_hdf('foo_1.h5', 'x')\n",
    "dd.io.save('kimore224norm_blazepose_xyz_noOverlap_dicts.h5', dict_list)\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained resnet_classifier model\n",
    "\n",
    "# remove last layer (Dense=20 MoVi classification layer)\n",
    "    # https://stackoverflow.com/questions/41668813/how-to-add-and-remove-new-layers-in-keras-after-loading-weights\n",
    "    # https://stackoverflow.com/questions/41378461/how-to-use-models-from-keras-applications-for-transfer-learnig/41386444#41386444\n",
    "\n",
    "# make multi-output layer with dimensions (Dense=5) and (Dense=3) for exercise and rating respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': array([[[116, 208,  34],\n",
      "        [116, 207,  35],\n",
      "        [117, 207,  35],\n",
      "        ...,\n",
      "        [ 86,   2,  90],\n",
      "        [ 85,   2,  90],\n",
      "        [ 84,   2,  90]],\n",
      "\n",
      "       [[116, 208,  34],\n",
      "        [116, 207,  35],\n",
      "        [117, 207,  35],\n",
      "        ...,\n",
      "        [ 86,   2,  90],\n",
      "        [ 85,   2,  90],\n",
      "        [ 84,   2,  90]],\n",
      "\n",
      "       [[116, 208,  34],\n",
      "        [116, 207,  35],\n",
      "        [117, 207,  35],\n",
      "        ...,\n",
      "        [ 86,   2,  90],\n",
      "        [ 85,   2,  90],\n",
      "        [ 84,   2,  90]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[121, 208,  39],\n",
      "        [121, 208,  39],\n",
      "        [122, 208,  40],\n",
      "        ...,\n",
      "        [ 87,  11,  89],\n",
      "        [ 86,  11,  89],\n",
      "        [ 85,  11,  89]],\n",
      "\n",
      "       [[121, 208,  40],\n",
      "        [121, 208,  40],\n",
      "        [122, 208,  41],\n",
      "        ...,\n",
      "        [ 87,  11,  88],\n",
      "        [ 86,  11,  88],\n",
      "        [ 85,  11,  88]],\n",
      "\n",
      "       [[121, 208,  40],\n",
      "        [121, 208,  40],\n",
      "        [122, 208,  41],\n",
      "        ...,\n",
      "        [ 87,  11,  88],\n",
      "        [ 86,  11,  88],\n",
      "        [ 85,  11,  88]]], dtype=uint8), 'group': 'B', 'subject_id': 'ID1', 'slice': 0, 'TS': 41.0, 'PO': 15.0, 'CF': 26.0, 'rating': 3, 'rating_onehot': array([0., 0., 1.]), 'exercise': 1, 'exercise_onehot': array([1., 0., 0., 0., 0.])}\n",
      "B_ID1_Es1_seq0.png\n"
     ]
    }
   ],
   "source": [
    "# load kimore_filenames.txt and kimore_dicts.h5\n",
    "    # both have length = 385\n",
    "    # deepdish info: https://deepdish.readthedocs.io/en/latest/io.html#lists-and-tuples\n",
    "\n",
    "with open(\"kimore224norm_blazepose_xyz_noOverlap_filenames.txt\", \"r\") as txt_file:\n",
    "    file_contents = txt_file.readlines()\n",
    "\n",
    "kimore_filenames = file_contents[0].split(' ')[:-1]\n",
    "kimore_dicts = dd.io.load('kimore224norm_blazepose_xyz_noOverlap_dicts.h5')\n",
    "print(kimore_dicts[0])\n",
    "print(kimore_filenames[0])\n",
    "    \n",
    "# # randomly select 80% training, 20% validation (or maybe reserve some for test??)\n",
    "# split = 0.8\n",
    "\n",
    "# train_split = round(split * len(kimore_filenames))\n",
    "# train_files = random.sample(kimore_filenames, train_split)\n",
    "# val_files = [f for f in kimore_filenames if f not in train_files]\n",
    "\n",
    "# # assert that the train and val files are unique\n",
    "# #print([file for file in train_files if file in val_files])\n",
    "\n",
    "# # get indexes\n",
    "# train_idx = [i for i in range(len(kimore_filenames)) if kimore_filenames[i] in train_files]\n",
    "# val_idx = [i for i in range(len(kimore_filenames)) if kimore_filenames[i] in val_files]\n",
    "\n",
    "# # NN input = kimore_dicts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = []\n",
    "for dic in kimore_dicts:\n",
    "    group = dic['group']\n",
    "    sub_id = dic['subject_id']\n",
    "    subject = [group, sub_id]\n",
    "    subject_list.append(subject)\n",
    "    \n",
    "unique_subjects = [list(x) for x in set(tuple(x) for x in subject_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815\n",
      "5809\n",
      "0.1402995352039938\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.15\n",
    "split = 1\n",
    "while (split > test_split):\n",
    "    test_subject_num = round(0.1 * len(unique_subjects))\n",
    "    test_subject_list = np.array(random.sample(unique_subjects, test_subject_num))\n",
    "    test_dicts = []\n",
    "    test_idx = []\n",
    "    for d in range(len(kimore_dicts)):\n",
    "        group = kimore_dicts[d]['group']\n",
    "        sub_id = kimore_dicts[d]['subject_id']\n",
    "        if (group in test_subject_list[:, 0]):\n",
    "            if (sub_id in test_subject_list[:, 1]):\n",
    "                test_dicts.append(kimore_dicts[d])\n",
    "                test_idx.append(d)          \n",
    "                \n",
    "    split = len(test_dicts) / len(kimore_dicts)\n",
    "\n",
    "print(len(test_dicts))\n",
    "print(len(kimore_dicts))\n",
    "print(len(test_dicts) / len(kimore_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_test_idx = [i for i in list(range(5809)) if i not in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [kimore_filenames[i] for i in test_idx]\n",
    "non_test_files = [kimore_filenames[i] for i in non_test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3998\n",
      "999\n",
      "5809\n"
     ]
    }
   ],
   "source": [
    "train_file_num = round(0.8 * len(non_test_files))\n",
    "train_files = random.sample(non_test_files, train_file_num)\n",
    "train_idx = [i for i in range(len(non_test_files)) if non_test_files[i] in train_files]\n",
    "print(len(train_files))\n",
    "\n",
    "val_files = [f for f in non_test_files if f not in train_files]\n",
    "val_idx = [i for i in range(len(non_test_files)) if non_test_files[i] in val_files]\n",
    "print(len(val_files))\n",
    "\n",
    "total = len(test_files) + len(train_files) + len(val_files)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3998, 224, 224, 3)\n",
      "(3998, 3)\n",
      "(3998, 5)\n"
     ]
    }
   ],
   "source": [
    "# get numpy arrays of train inputs and outputs\n",
    "train_input_list = []\n",
    "train_ratings_list = []\n",
    "train_exercises_list = []\n",
    "\n",
    "for idx in train_idx:\n",
    "    train_dict = kimore_dicts[idx]\n",
    "    \n",
    "    train_input_list.append(train_dict[\"image\"])\n",
    "    train_ratings_list.append(train_dict[\"rating_onehot\"])\n",
    "    train_exercises_list.append(train_dict[\"exercise_onehot\"])\n",
    "\n",
    "\n",
    "train_inputs = np.stack(train_input_list)\n",
    "train_ratings = np.stack(train_ratings_list)\n",
    "train_exercises = np.stack(train_exercises_list)\n",
    "\n",
    "print(train_inputs.shape)\n",
    "print(train_ratings.shape)\n",
    "print(train_exercises.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 224, 224, 3)\n",
      "(999, 3)\n",
      "(999, 5)\n"
     ]
    }
   ],
   "source": [
    "# get numpy arrays of val inputs and outputs\n",
    "val_input_list = []\n",
    "val_ratings_list = []\n",
    "val_exercises_list = []\n",
    "\n",
    "for idx in val_idx:\n",
    "    val_dict = kimore_dicts[idx]\n",
    "    \n",
    "    val_input_list.append(val_dict[\"image\"])\n",
    "    val_ratings_list.append(val_dict[\"rating_onehot\"])\n",
    "    val_exercises_list.append(val_dict[\"exercise_onehot\"])\n",
    "\n",
    "\n",
    "val_inputs = np.stack(val_input_list)\n",
    "val_ratings = np.stack(val_ratings_list)\n",
    "val_exercises = np.stack(val_exercises_list)\n",
    "\n",
    "print(val_inputs.shape)\n",
    "print(val_ratings.shape)\n",
    "print(val_exercises.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(812, 224, 224, 3)\n",
      "(812, 3)\n",
      "(812, 5)\n"
     ]
    }
   ],
   "source": [
    "test_input_list = []\n",
    "test_ratings_list = []\n",
    "test_exercises_list = []\n",
    "\n",
    "for idx in test_idx:\n",
    "    test_dict = kimore_dicts[idx]\n",
    "    test_input_list.append(test_dict[\"image\"])\n",
    "    test_ratings_list.append(test_dict[\"rating_onehot\"])\n",
    "    test_exercises_list.append(test_dict[\"exercise_onehot\"])\n",
    "\n",
    "test_inputs = np.stack(test_input_list)\n",
    "test_ratings = np.stack(test_ratings_list)\n",
    "test_exercises = np.stack(test_exercises_list)\n",
    "\n",
    "print(test_inputs.shape)\n",
    "print(test_ratings.shape)\n",
    "print(test_exercises.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run deep learning within pipeline of pose detector\n",
    "# doesn't matter which action classifier for now\n",
    "# just needs to take skeleton and feed it through\n",
    "# 2 parallel deep learning models on camera - pose and classifier\n",
    "# resnet - good baseline that we know will work\n",
    "# in the future, can use MobileNet for speed and see the accuracy tradeoff\n",
    "\n",
    "\n",
    "# SLURM documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
